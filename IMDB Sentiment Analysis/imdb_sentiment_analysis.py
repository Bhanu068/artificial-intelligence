# -*- coding: utf-8 -*-
"""IMDB Sentiment Analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hXZ2DGpEPVnNxdCSwG2C0ChvdpDZY4O7
"""

import pandas as pd
import numpy as np
import string
import nltk
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

df = pd.read_csv('/content/drive/MyDrive/Colab Datasets/IMDB_Dataset.csv')

df.head()

df.info()

tokenize = Tokenizer()
tokenize.fit_on_texts(df['review'])
X_seq = tokenize.texts_to_sequences(df['review'])
X_pad = pad_sequences(X_seq, maxlen = 500)

vocab_size = len(tokenize.word_index) + 1

tokenize2 = Tokenizer()
tokenize2.fit_on_texts(df['sentiment'])
Y_seq = tokenize2.texts_to_sequences(df['sentiment'])
Y_pad = pad_sequences(Y_seq, maxlen = 1)

Y = df['sentiment'].replace({'positive' : 1, 'negative': 0})

model_lstm = keras.models.Sequential([
        keras.layers.Embedding(vocab_size, 40, input_length = 500),
        keras.layers.Dropout(0.5),
        keras.layers.LSTM(100),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(1, activation = 'sigmoid')
])

model_lstm.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
model_lstm.summary()

model_lstm.fit(X_pad, Y, validation_split = 0.2, batch_size = 16, epochs = 10)

model_lstm.save("movie_sentiment_analysis_lstm.h5")

with open("movie_sentiment_analysis_lstm.json", "w") as json_file:
  model_json = model_lstm.to_json() 
  json_file.write(model_json) 

# Saving weights of the model to a HDF5 file 
model_lstm.save_weights("movie_sentiment_analysis_lstm_weights.h5")

model_gru = keras.models.Sequential([
        keras.layers.Embedding(vocab_size, 40, input_length = 500),
        keras.layers.Dropout(0.5),
        keras.layers.GRU(100),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(1, activation = 'sigmoid')
])

model_gru.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
model_gru.summary()

model_gru.fit(X_pad, Y, validation_split = 0.2, batch_size = 16, epochs = 5)

model_gru.save("movie_sentiment_analysis_gru.h5")

with open("movie_sentiment_analysis_gru.json", "w") as json_file:
  model_gru_json = model_gru.to_json() 
  json_file.write(model_gru_json) 

# Saving weights of the model to a HDF5 file 
model_gru.save_weights("movie_sentiment_analysis_gru_weights.h5")

model_bilstm = keras.models.Sequential([
        keras.layers.Embedding(vocab_size, 40, input_length = 500),
        keras.layers.Dropout(0.5),
        keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences = True)),
        keras.layers.Bidirectional(keras.layers.LSTM(100)),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(1, activation = 'sigmoid')
])

model_bilstm.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
model_bilstm.summary()

model_bilstm.fit(X_pad, Y, validation_split = 0.2, batch_size = 16, epochs = 5)

model_bilstm.save("movie_sentiment_analysis_bilstm.h5")

with open("movie_sentiment_analysis_bilstm.json", "w") as json_file:
  model_gru_json = model_bilstm.to_json() 
  json_file.write(model_gru_json) 

# Saving weights of the model to a HDF5 file 
model_bilstm.save_weights("movie_sentiment_analysis_bilstm_weights.h5")

# Without dropout
model.fit(X_pad, Y, validation_split = 0.2, batch_size = 16, epochs = 10)