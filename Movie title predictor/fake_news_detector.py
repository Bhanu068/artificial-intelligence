# -*- coding: utf-8 -*-
"""Fake news detector

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MjXEFWdfUmo7XCkMMIF_zl649l3yDPO1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk, pickle
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import load_model

train_df = pd.read_csv('/content/drive/MyDrive/Colab Datasets/fake-news/train.csv')

train_df.head()

sns.countplot(data = train_df, x = train_df['label'])

train_df.dropna(inplace = True)

tokenizer = Tokenizer()
tokenizer.fit_on_texts(train_df['text'])
X_seq = tokenizer.texts_to_sequences(train_df['text'])
X_pad = pad_sequences(X_seq, maxlen = 500)

vocab_size = len(tokenizer.word_index) + 1

Y = train_df['label']

model_lstm = keras.models.Sequential([
        keras.layers.Embedding(vocab_size, 40, input_length = 500),
        tf.compat.v1.keras.layers.CuDNNLSTM(100),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(1, activation = 'sigmoid')
])

model_lstm.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
model_lstm.summary()

model_lstm.fit(X_pad, Y, validation_split = 0.2, batch_size = 16, epochs = 5)

model_lstm.save("fake_news_detector_model_lstm.h5")

with open("fake_news_detector_model_lstm.json", "w") as json_file:
  model_json = model_lstm.to_json() 
  json_file.write(model_json) 
  
# Saving weights of the model to a HDF5 file 
model_lstm.save_weights("fake_news_detector_model_lstm_weights.h5")

model_gru = keras.models.Sequential([
        keras.layers.Embedding(vocab_size, 40, input_length = 500),
        keras.layers.GRU(100),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(1, activation = 'sigmoid')
])

model_gru.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
model_gru.summary()

model_gru.fit(X_pad, Y, validation_split = 0.2, batch_size = 16, epochs = 5)

model_gru.save("fake_news_detector_model_gru.h5")

with open("fake_news_detector_model_gru.json", "w") as json_file:
  model_gru_json = model_gru.to_json() 
  json_file.write(model_gru_json)

# Saving weights of the model to a HDF5 file 
model_gru.save_weights("fake_news_detector_model_gru_weights.h5")

model_bilstm = keras.models.Sequential([
        keras.layers.Embedding(vocab_size, 40, input_length = 500),
        keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True)),
        keras.layers.Bidirectional(keras.layers.LSTM(100)),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(1, activation = 'sigmoid')
])

model_bilstm.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
model_bilstm.summary()

model_bilstm.fit(X_pad, Y, validation_split = 0.2, batch_size = 16, epochs = 5)

model_bilstm.save("fake_news_detector_model_bilstm.h5")

with open("fake_news_detector_model_bilstm.json", "w") as json_file:
  model_bilstm_json = model_bilstm.to_json() 
  json_file.write(model_bilstm_json) 

# Saving weights of the model to a HDF5 file 
model_bilstm.save_weights("fake_news_detector_model_bilstm_weights.h5")

# Without dropout
# model.fit(X_pad, Y, validation_split = 0.2, batch_size = 16, epochs = 10)